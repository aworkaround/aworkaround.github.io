---
layout: post
authors: ["devcrypted"]
media_subpath: /assets/img/
pin: false
video_prefix: https://youtu.be/
playlist_prefix: https://youtube.com/playlist?list=
github_prefix: https://github.com/devcrypted/
youtube_logo: <i class="fa-brands fa-youtube"></i>

# Should be changed according to post
published: true
title: "Integrate AI with VS Code | GitHub Copilot Free Alternative"
permalink: integrate-ai-with-vs-code
date: 2024-10-06 00:00 +0530
categories: ["Large Language Models"]
tags: ["Ollama", "LLM", "AI", "VS Code"]
image: https://img.youtube.com/vi/cxP6lcjkQCc/maxresdefault.jpg
description: Learn how can we install Ollama on our computer and start using popular LLM (Large Language Models) locally for free. We will also learn how can we integrate it with VS Code to speed up our development and make it less error prone by using AI as our code assistant

# Variables
video_id: cxP6lcjkQCc
playlist_id: PL2JBbPWIA_TqZwCLtd6wi6A5-Q8U9QlHT
github_repo: ""
---

- [<i class="fa-brands fa-github"></i> &nbsp; GitHub Repository]({{page.github_prefix}}{{page.github_repo}})
- [<i class="fa-brands fa-youtube"></i> &nbsp; Watch on YouTube]({{page.video_prefix}}{{page.video_id}})
- [<i class="fa-solid fa-list"></i> &nbsp; YouTube Playlist]({{page.playlist_prefix}}{{page.playlist_id}})

---

{% include embed/youtube.html id=page.video_id %}

---

## PREREQUISITES

1. Install VS Code [Link](https://code.visualstudio.com/)
2. Install Ollama locally for free [Link](http://ollama.com/)
3. Pull LLM (Large Language Model) using Ollama using command ```ollama pull <image-name>```. Popular LLMs
   1. ```ollama pull llama3.2:3b```  - Use it on old laptops/desktops
   2. ```ollama pull llama3.1:8b```  - Use it on normal laptops/desktops
   3. ```ollama pull llama3.1:70b```  - Use it on normal 32GB+ RAM laptop/desktop
   4. ```ollama pull deepseek-coder-v2:16b```  - Use it Laptop/desktop for coding specifically
   5. ```ollama pull codellama:7b```  - Lighter LLM for Lower end laptops/desktops

## INTEGRATING WITH VS CODE

1. Install VS Code Extension ```Continue.continue``` and ```ex3ndr.llama-coder```

## RUNNING A LOCAL WEB VERSION

1. Install Docker Desktop
2. Run command ```docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main```
3. Access the Web UI at ```http://localhost:3000```
4. Sign Up using new username and password. You can use any valid email address as your username.